---
title: "White Book on Safety Evaluation of Generative Large Models (2024)"
collection: publications
category: books
permalink: /publication/2024-12-28-book-title-number-1
excerpt: 'State Key Laboratory of AI Safety, Chinese Academy of Sciences; The Third Research Institute of Ministry of Public Security; Ant Security Lab.'
date: 2024-12-28
venue: 'CCF China Data 2024'
# slidesurl: 'https://academicpages.github.io/files/slides3.pdf'
# paperurl: 'https://academicpages.github.io/files/paper3.pdf'
# citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---

Since 2023, the rapid rise of generative large models has been profoundly reshaping the global landscape of artificial intelligence technology and injecting new vitality into China's digital economy and intelligent transformation. With the widespread application of this technology, its potential security risks have gradually emerged, including issues such as privacy leakage, malicious abuse, technical vulnerabilities, and compliance challenges. The country attaches great importance to related risks. Policy documents such as the "Interim Measures for the Administration of Generative Artificial Intelligence Services" have clearly emphasized the requirements for technical security and regulatory norms, pointing out the direction for promoting the healthy development of the technology.

Generative large models have shown great potential in information generation, knowledge mining, and interactive experience, but they also bring new tests to social trust and public interests. With the rapid development of technology, establishing a scientific and systematic security assessment framework has become an urgent task. The establishment of this framework will help clarify assessment dimensions and standards, reduce potential risks in technology applications, and provide authoritative guidance for industry practices.

This white paper focuses on the security assessment of generative large models, systematically analyzing technical challenges and response strategies from the current development status to security risks, from assessment methods to practical cases. It is hoped to provide useful references for academic research, industrial practice, and policy formulation, assist in the research and application development of large model security, and lay a foundation for building a safe and trustworthy artificial intelligence ecosystem.
